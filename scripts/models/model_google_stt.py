#!/usr/bin/env python3
"""
Google Cloud Speech-to-Text V2 æ¨¡å‹åŒ…è£å™¨
ç‰ˆæœ¬: 2.0 (2025å¹´1æœˆä¿®æ­£ç‰ˆ)

ä¿®æ­£é‡é»:
1. âœ… æ­£ç¢ºä½¿ç”¨å€åŸŸç«¯é» ({REGION}-speech.googleapis.com)
2. âœ… æ­£ç¢ºçš„ recognizer è·¯å¾‘æ ¼å¼
3. âœ… æ”¯æ´ Chirp 3 / Chirp Telephony / Chirp 2 ç­‰æ¨¡å‹
4. âœ… æ­£ç¢ºå¯¦ä½œ PhraseSet é©æ‡‰åŠŸèƒ½
5. âœ… è‡ªå‹•å€åŸŸå›é€€æ©Ÿåˆ¶
ä¿®æ­£_2026.01.12-16:00:
1. âœ… éŸ³è¨Šæ ¼å¼è‡ªå‹•è½‰æ›ï¼ˆè§£æ±º 400 Audio encoding éŒ¯èª¤ï¼‰
2. âœ… æ­£ç¢ºçš„ recognizer è·¯å¾‘æ ¼å¼ï¼ˆä½¿ç”¨ recognizers/_)
3. âœ… æ˜ç¢ºæŒ‡å®šéŸ³è¨Šç·¨ç¢¼åƒæ•¸
4. âœ… å€åŸŸç«¯é»é…ç½®
"""

import os
import sys
import wave
import struct
import tempfile
import subprocess
from pathlib import Path
from typing import List, Dict, Optional, Tuple

# ä¿®æ­£ import è·¯å¾‘
if __name__ == "__main__":
    project_root = Path(__file__).parent.parent.parent
    sys.path.insert(0, str(project_root))

# ============================================================================
# å…§å»ºèªè­‰è¨­å®šï¼ˆåœ¨ import Google Client ä¹‹å‰ï¼‰
# ============================================================================
def setup_credentials():
    """è‡ªå‹•è¨­å®š Google Cloud èªè­‰"""
    default_key_path = Path(__file__).parent.parent.parent / "utils" / "google-speech-key.json"
    
    if not os.getenv('GOOGLE_APPLICATION_CREDENTIALS'):
        if default_key_path.exists():
            os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = str(default_key_path)

# è¨­å®šèªè­‰
setup_credentials()

from google.cloud.speech_v2 import SpeechClient
from google.cloud.speech_v2.types import cloud_speech
from google.api_core.client_options import ClientOptions

try:
    from utils.logger import get_logger
    from utils.google_stt_config_manager import GoogleSTTConfigManager
except ImportError:
    sys.path.insert(0, str(Path(__file__).parent.parent.parent))
    from utils.logger import get_logger
    from utils.google_stt_config_manager import GoogleSTTConfigManager


# ============================================================================
# éŸ³è¨Šæ ¼å¼è½‰æ›å·¥å…·
# ============================================================================
class AudioConverter:
    """éŸ³è¨Šæ ¼å¼è½‰æ›å™¨ - ç¢ºä¿éŸ³è¨Šç¬¦åˆ Google STT è¦æ±‚"""
    
    SUPPORTED_SAMPLE_RATES = [8000, 16000, 32000, 48000]
    TARGET_SAMPLE_RATE = 16000  # Google STT æ¨è–¦çš„å–æ¨£ç‡
    
    @staticmethod
    def get_wav_info(audio_path: str) -> Dict:
        """
        è®€å– WAV æª”æ¡ˆè³‡è¨Š
        
        Returns:
            dict: {
                'sample_rate': int,
                'channels': int,
                'sample_width': int (bytes),
                'frames': int,
                'duration': float (seconds),
                'encoding': str
            }
        """
        try:
            with wave.open(audio_path, 'rb') as wav:
                return {
                    'sample_rate': wav.getframerate(),
                    'channels': wav.getnchannels(),
                    'sample_width': wav.getsampwidth(),
                    'frames': wav.getnframes(),
                    'duration': wav.getnframes() / wav.getframerate(),
                    'encoding': 'LINEAR16' if wav.getsampwidth() == 2 else f'UNKNOWN_{wav.getsampwidth()*8}bit'
                }
        except Exception as e:
            return {'error': str(e)}
    
    @staticmethod
    def convert_to_linear16(
        input_path: str,
        output_path: str = None,
        target_sample_rate: int = 16000
    ) -> str:
        """
        å°‡éŸ³è¨Šè½‰æ›ç‚º LINEAR16 PCM æ ¼å¼
        
        Args:
            input_path: è¼¸å…¥éŸ³æª”è·¯å¾‘
            output_path: è¼¸å‡ºè·¯å¾‘ï¼ˆNone å‰‡ä½¿ç”¨è‡¨æ™‚æª”æ¡ˆï¼‰
            target_sample_rate: ç›®æ¨™å–æ¨£ç‡
        
        Returns:
            str: è½‰æ›å¾Œçš„æª”æ¡ˆè·¯å¾‘
        """
        if output_path is None:
            # å»ºç«‹è‡¨æ™‚æª”æ¡ˆ
            fd, output_path = tempfile.mkstemp(suffix='.wav')
            os.close(fd)
        
        # ä½¿ç”¨ ffmpeg è½‰æ›
        cmd = [
            'ffmpeg', '-y',
            '-i', input_path,
            '-acodec', 'pcm_s16le',  # LINEAR16 (16-bit signed little-endian)
            '-ar', str(target_sample_rate),  # å–æ¨£ç‡
            '-ac', '1',  # å–®è²é“
            output_path
        ]
        
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if result.returncode != 0:
                raise RuntimeError(f"ffmpeg è½‰æ›å¤±æ•—: {result.stderr}")
            
            return output_path
        
        except FileNotFoundError:
            raise RuntimeError("æ‰¾ä¸åˆ° ffmpegï¼Œè«‹å®‰è£ ffmpeg")
    
    @staticmethod
    def needs_conversion(audio_path: str) -> Tuple[bool, Dict]:
        """
        æª¢æŸ¥éŸ³è¨Šæ˜¯å¦éœ€è¦è½‰æ›
        
        Returns:
            Tuple[bool, Dict]: (éœ€è¦è½‰æ›, éŸ³è¨Šè³‡è¨Š)
        """
        info = AudioConverter.get_wav_info(audio_path)
        
        if 'error' in info:
            # ç„¡æ³•è®€å–ï¼Œå¯èƒ½ä¸æ˜¯æ¨™æº– WAVï¼Œéœ€è¦è½‰æ›
            return True, info
        
        needs_convert = False
        reasons = []
        
        # æª¢æŸ¥ç·¨ç¢¼
        if info['sample_width'] != 2:  # ä¸æ˜¯ 16-bit
            needs_convert = True
            reasons.append(f"é 16-bit ({info['sample_width']*8}-bit)")
        
        # æª¢æŸ¥è²é“
        if info['channels'] != 1:
            needs_convert = True
            reasons.append(f"éå–®è²é“ ({info['channels']} channels)")
        
        # æª¢æŸ¥å–æ¨£ç‡
        if info['sample_rate'] not in AudioConverter.SUPPORTED_SAMPLE_RATES:
            needs_convert = True
            reasons.append(f"å–æ¨£ç‡ä¸æ”¯æ´ ({info['sample_rate']} Hz)")
        
        info['needs_conversion'] = needs_convert
        info['conversion_reasons'] = reasons
        
        return needs_convert, info


class GoogleSTTModel:
    """Google Cloud Speech-to-Text V2 API åŒ…è£å™¨ï¼ˆä¿®æ­£ç‰ˆ v2ï¼‰"""
    
    def __init__(
        self,
        project_id: str = None,
        location: str = None,
        model: str = "chirp_3",
        language_code: str = "cmn-Hant-TW",
        auto_config: bool = True,
        auto_convert_audio: bool = True  # æ–°å¢ï¼šè‡ªå‹•è½‰æ›éŸ³è¨Š
    ):
        """åˆå§‹åŒ– Google STT æ¨¡å‹"""
        self.logger = get_logger(self.__class__.__name__)
        self.project_id = project_id or os.getenv('GOOGLE_CLOUD_PROJECT', 'dazzling-seat-315406')
        self.language_code = language_code
        self.auto_convert_audio = auto_convert_audio
        self._temp_files = []  # è¿½è¹¤è‡¨æ™‚æª”æ¡ˆ
        
        # ç¢ºä¿èªè­‰å·²è¨­å®š
        setup_credentials()
        
        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        if auto_config:
            try:
                self.config_manager = GoogleSTTConfigManager(self.project_id)
                # å–å¾—æœ€ä½³é…ç½®ï¼ˆè¿”å›ä¸‰å…ƒçµ„ï¼šmodel, region, endpointï¼‰
                config_result = self.config_manager.get_optimal_config(
                    model=model or "chirp_3",
                    preferred_region=location
                )
                
                # ç›¸å®¹æ–°èˆŠç‰ˆæœ¬çš„é…ç½®ç®¡ç†å™¨
                if isinstance(config_result, tuple) and len(config_result) == 3:
                    self.model, self.location, self.api_endpoint = config_result
                else:
                    self.model, self.location = config_result
                    self.api_endpoint = f"{self.location}-speech.googleapis.com"
                
                self.logger.info("âœ… ä½¿ç”¨å‹•æ…‹é…ç½®ç®¡ç†")
            except Exception as e:
                self.logger.warning(f"âš ï¸ å‹•æ…‹é…ç½®å¤±æ•—ï¼Œä½¿ç”¨é è¨­å€¼: {e}")
                self.model = model or "chirp_3"
                self.location = location or "us"
                self.api_endpoint = f"{self.location}-speech.googleapis.com"
                self.config_manager = None
        else:
            self.model = model or "chirp_3"
            self.location = location or "us"
            self.api_endpoint = f"{self.location}-speech.googleapis.com"
            self.config_manager = None
            self.logger.warning("âš ï¸ æ‰‹å‹•é…ç½®æ¨¡å¼ï¼ˆä¸å»ºè­°ï¼‰")
        
        # å»ºç«‹å®¢æˆ¶ç«¯ï¼ˆä½¿ç”¨å€åŸŸç«¯é»ï¼‰
        try:
            client_options = ClientOptions(api_endpoint=self.api_endpoint)
            self.client = SpeechClient(client_options=client_options)
            
            self.logger.info(f"âœ… Google STT åˆå§‹åŒ–æˆåŠŸ")
            self.logger.info(f"   å°ˆæ¡ˆ: {self.project_id}")
            self.logger.info(f"   å€åŸŸ: {self.location}")
            self.logger.info(f"   ç«¯é»: {self.api_endpoint}")
            self.logger.info(f"   æ¨¡å‹: {self.model}")
            self.logger.info(f"   èªè¨€: {self.language_code}")
            self.logger.info(f"   è‡ªå‹•è½‰æª”: {'âœ… å•Ÿç”¨' if auto_convert_audio else 'âŒ åœç”¨'}")
        except Exception as e:
            self.logger.error(f"âŒ Google STT åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    def __del__(self):
        """æ¸…ç†è‡¨æ™‚æª”æ¡ˆ"""
        for temp_file in self._temp_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except:
                pass
    
    def _prepare_audio(self, audio_file: str) -> Tuple[bytes, int]:
        """
        æº–å‚™éŸ³è¨Šè³‡æ–™ï¼ˆå¿…è¦æ™‚é€²è¡Œè½‰æ›ï¼‰
        
        Returns:
            Tuple[bytes, int]: (éŸ³è¨Šè³‡æ–™, å–æ¨£ç‡)
        """
        audio_path = Path(audio_file)
        
        if self.auto_convert_audio:
            # æª¢æŸ¥æ˜¯å¦éœ€è¦è½‰æ›
            needs_convert, info = AudioConverter.needs_conversion(str(audio_path))
            
            if needs_convert:
                reasons = info.get('conversion_reasons', ['æ ¼å¼ä¸ç›¸å®¹'])
                self.logger.info(f"ğŸ”„ éŸ³è¨Šéœ€è¦è½‰æ›: {', '.join(reasons)}")
                
                # è½‰æ›éŸ³è¨Š
                converted_path = AudioConverter.convert_to_linear16(
                    str(audio_path),
                    target_sample_rate=16000
                )
                self._temp_files.append(converted_path)
                
                self.logger.debug(f"âœ… éŸ³è¨Šå·²è½‰æ›: {converted_path}")
                
                # è®€å–è½‰æ›å¾Œçš„éŸ³è¨Š
                with open(converted_path, 'rb') as f:
                    audio_content = f.read()
                
                return audio_content, 16000
            else:
                # ä¸éœ€è¦è½‰æ›ï¼Œç›´æ¥è®€å–
                sample_rate = info.get('sample_rate', 16000)
                with open(audio_file, 'rb') as f:
                    audio_content = f.read()
                
                return audio_content, sample_rate
        else:
            # ä¸è‡ªå‹•è½‰æ›ï¼Œç›´æ¥è®€å–
            with open(audio_file, 'rb') as f:
                audio_content = f.read()
            
            # å˜—è©¦å–å¾—å–æ¨£ç‡
            info = AudioConverter.get_wav_info(str(audio_path))
            sample_rate = info.get('sample_rate', 16000)
            
            return audio_content, sample_rate
    
    def transcribe_file(
        self,
        audio_file: str,
        phrases: List[Dict] = None,
        enable_word_time_offsets: bool = True, # æ”¯æ´æ¨™é»ç¬¦è™Ÿ 
        **kwargs # æ¥æ”¶ä¸¦å¿½ç•¥ä¸æ”¯æ´çš„åƒæ•¸ (ä¾‹å¦‚ diarization)
        # 17:10å¢åŠ åƒæ•¸
    ) -> Dict:
        """
        è¾¨è­˜éŸ³æª”ï¼ˆä¿®æ­£ç‰ˆ v2ï¼‰
        
        Args:
            audio_file: éŸ³æª”è·¯å¾‘
            phrases: è©å½™è¡¨åˆ—è¡¨ [{"value": "è©å½™", "boost": 10}, ...]
            enable_word_time_offsets: æ˜¯å¦å•Ÿç”¨å­—è©æ™‚é–“æˆ³
        
        Returns:
            è¾¨è­˜çµæœå­—å…¸
        """
        try:
            # æº–å‚™éŸ³è¨Šï¼ˆå¿…è¦æ™‚è‡ªå‹•è½‰æ›ï¼‰
            audio_content, sample_rate = self._prepare_audio(audio_file)
            
            # ====================================================================
            # ä¿®æ­£ï¼šæ­£ç¢ºçš„ recognizer è·¯å¾‘æ ¼å¼
            # V2 API ä½¿ç”¨ recognizers/_ è€Œä¸æ˜¯ recognizers/{model_name}
            # ====================================================================
            recognizer_path = (
                f"projects/{self.project_id}/locations/{self.location}/recognizers/_"
            )
            
            self.logger.debug(f"Recognizer è·¯å¾‘: {recognizer_path}")
            
            # ====================================================================
            # ä¿®æ­£ï¼šæ˜ç¢ºæŒ‡å®šéŸ³è¨Šç·¨ç¢¼ï¼ˆä¸ä½¿ç”¨ auto_decoding_configï¼‰
            # ====================================================================
            explicit_decoding = cloud_speech.ExplicitDecodingConfig(
                encoding=cloud_speech.ExplicitDecodingConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=sample_rate,
                audio_channel_count=1
            )
            
            config = cloud_speech.RecognitionConfig(
                explicit_decoding_config=explicit_decoding,
                language_codes=[self.language_code],
                model=self.model,
                features=cloud_speech.RecognitionFeatures(
                    enable_word_time_offsets=enable_word_time_offsets,
                    enable_automatic_punctuation=False
                )
            )
            
            # å¦‚æœæœ‰è©å½™è¡¨ï¼Œä½¿ç”¨ inline phrase_hints
            if phrases and len(phrases) > 0:
                phrase_hints = []
                for phrase_dict in phrases:
                    if isinstance(phrase_dict, dict) and 'value' in phrase_dict:
                        phrase_hints.append(phrase_dict['value'])
                    elif isinstance(phrase_dict, str):
                        phrase_hints.append(phrase_dict)
                
                if phrase_hints:
                    # é™åˆ¶æ•¸é‡ï¼ˆChirp 3 æ”¯æ´ 1000ï¼Œå…¶ä»–æ¨¡å‹ 500ï¼‰
                    max_phrases = 1000 if 'chirp_3' in self.model else 500
                    phrase_hints = phrase_hints[:max_phrases]
                    
                    # ä½¿ç”¨ inline adaptationï¼ˆæ­£ç¢ºçš„ V2 API æ–¹å¼ï¼‰
                    config.adaptation = cloud_speech.SpeechAdaptation(
                        phrase_sets=[
                            cloud_speech.SpeechAdaptation.AdaptationPhraseSet(
                                inline_phrase_set=cloud_speech.PhraseSet(
                                    phrases=[
                                        cloud_speech.PhraseSet.Phrase(value=hint, boost=10)
                                        for hint in phrase_hints
                                    ]
                                )
                            )
                        ]
                    )
                    self.logger.debug(f"âœ… è¼‰å…¥ {len(phrase_hints)} å€‹è©å½™æç¤º")
            
            # å»ºç«‹è«‹æ±‚
            request = cloud_speech.RecognizeRequest(
                recognizer=recognizer_path,
                config=config,
                content=audio_content
            )
            
            # åŸ·è¡Œè¾¨è­˜
            self.logger.debug(f"ç™¼é€è¾¨è­˜è«‹æ±‚: {Path(audio_file).name}")
            response = self.client.recognize(request=request)
            
            # è™•ç†çµæœ
            if not response.results:
                self.logger.warning(f"è¾¨è­˜çµæœç‚ºç©º: {audio_file}")
                return {
                    'transcript': '',
                    'transcript_raw': '',
                    'confidence': 0.0
                }
            
            # æå–æ–‡å­—
            transcript = ''
            confidence_sum = 0.0
            word_count = 0
            
            for result in response.results:
                if result.alternatives:
                    alternative = result.alternatives[0]
                    transcript += alternative.transcript
                    confidence_sum += alternative.confidence
                    word_count += 1
            
            avg_confidence = confidence_sum / word_count if word_count > 0 else 0.0
            
            self.logger.debug(f"âœ… è¾¨è­˜æˆåŠŸ: {Path(audio_file).name} (ä¿¡å¿ƒåº¦: {avg_confidence:.2%})")
            
            return {
                'transcript': transcript,
                'transcript_raw': transcript,
                'confidence': avg_confidence,
                'results': response.results
            }
        
        except Exception as e:
            error_msg = str(e)
            self.logger.error(f"âŒ è¾¨è­˜å¤±æ•— ({Path(audio_file).name}): {error_msg}")
            
            # å¦‚æœå•Ÿç”¨äº†è‡ªå‹•é…ç½®ï¼Œå˜—è©¦å›é€€åˆ°å‚™é¸å€åŸŸ
            if self.config_manager and "does not exist in the location" in error_msg:
                return self._try_fallback_regions(audio_file, phrases, enable_word_time_offsets, e)
            
            # å›å‚³éŒ¯èª¤è³‡è¨Š
            return {
                'transcript': '',
                'transcript_raw': '',
                'confidence': 0.0,
                'error': error_msg
            }
    
    def _try_fallback_regions(self, audio_file, phrases, enable_word_time_offsets, original_error):
        """å˜—è©¦ä½¿ç”¨å›é€€å€åŸŸ"""
        self.logger.warning(f"âš ï¸ ç•¶å‰å€åŸŸ '{self.location}' å¤±æ•—ï¼Œå˜—è©¦å›é€€å€åŸŸ...")
        
        if not self.config_manager:
            raise original_error
        
        model_config = self.config_manager.config['models'].get(self.model, {})
        fallback_regions = model_config.get('fallback_regions', [])
        
        for fallback_region in fallback_regions:
            if fallback_region == self.location:
                continue
            
            try:
                self.logger.info(f"å˜—è©¦å›é€€å€åŸŸ: {fallback_region}")
                
                # è‡¨æ™‚åˆ‡æ›å€åŸŸå’Œç«¯é»
                original_location = self.location
                original_endpoint = self.api_endpoint
                
                self.location = fallback_region
                self.api_endpoint = f"{fallback_region}-speech.googleapis.com"
                
                # é‡å»ºå®¢æˆ¶ç«¯
                client_options = ClientOptions(api_endpoint=self.api_endpoint)
                self.client = SpeechClient(client_options=client_options)
                
                # é‡æ–°å˜—è©¦è¾¨è­˜
                result = self.transcribe_file(audio_file, phrases, enable_word_time_offsets)
                
                if 'error' not in result:
                    self.logger.info(f"âœ… å›é€€æˆåŠŸï¼ä½¿ç”¨å€åŸŸ: {fallback_region}")
                    return result
                
            except Exception as e:
                self.logger.warning(f"å›é€€å€åŸŸ {fallback_region} ä¹Ÿå¤±æ•—: {e}")
                self.location = original_location
                self.api_endpoint = original_endpoint
                continue
        
        # æ‰€æœ‰å›é€€éƒ½å¤±æ•—
        self.logger.error("âŒ æ‰€æœ‰å›é€€å€åŸŸéƒ½å¤±æ•—")
        return {
            'transcript': '',
            'transcript_raw': '',
            'confidence': 0.0,
            'error': str(original_error)
        }
    
    def get_current_config(self) -> Dict:
        """ç²å–ç•¶å‰é…ç½®è³‡è¨Š"""
        return {
            'project_id': self.project_id,
            'location': self.location,
            'api_endpoint': self.api_endpoint,
            'model': self.model,
            'language_code': self.language_code,
            'auto_config_enabled': self.config_manager is not None,
            'auto_convert_audio': self.auto_convert_audio,
            'credentials_set': bool(os.getenv('GOOGLE_APPLICATION_CREDENTIALS'))
        }
    
    def print_config_info(self):
        """åˆ—å°é…ç½®è³‡è¨Š"""
        config = self.get_current_config()
        print("\nç•¶å‰ Google STT é…ç½®:")
        print(f"  å°ˆæ¡ˆID: {config['project_id']}")
        print(f"  å€åŸŸ: {config['location']}")
        print(f"  ç«¯é»: {config['api_endpoint']}")
        print(f"  æ¨¡å‹: {config['model']}")
        print(f"  èªè¨€: {config['language_code']}")
        print(f"  å‹•æ…‹é…ç½®: {'âœ… å•Ÿç”¨' if config['auto_config_enabled'] else 'âŒ åœç”¨'}")
        print(f"  è‡ªå‹•è½‰æª”: {'âœ… å•Ÿç”¨' if config['auto_convert_audio'] else 'âŒ åœç”¨'}")
        print(f"  èªè­‰è¨­å®š: {'âœ… å·²è¨­å®š' if config['credentials_set'] else 'âŒ æœªè¨­å®š'}")
        
        if config['credentials_set']:
            print(f"  é‡‘é‘°è·¯å¾‘: {os.getenv('GOOGLE_APPLICATION_CREDENTIALS')}")


def test_audio_conversion():
    """æ¸¬è©¦éŸ³è¨Šè½‰æ›åŠŸèƒ½"""
    print("\næ¸¬è©¦éŸ³è¨Šè½‰æ›åŠŸèƒ½")
    print("=" * 80)
    
    # æ¸¬è©¦ç”¨çš„éŸ³è¨Šæª”æ¡ˆè·¯å¾‘ï¼ˆéœ€è¦å­˜åœ¨ï¼‰
    test_files = [
        "/path/to/test.wav",
        # æ–°å¢æ‚¨çš„æ¸¬è©¦æª”æ¡ˆè·¯å¾‘
    ]
    
    for audio_file in test_files:
        if not os.path.exists(audio_file):
            print(f"âš ï¸ æ¸¬è©¦æª”æ¡ˆä¸å­˜åœ¨: {audio_file}")
            continue
        
        print(f"\næª”æ¡ˆ: {audio_file}")
        
        # å–å¾—éŸ³è¨Šè³‡è¨Š
        info = AudioConverter.get_wav_info(audio_file)
        print(f"  è³‡è¨Š: {info}")
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦è½‰æ›
        needs_convert, detailed_info = AudioConverter.needs_conversion(audio_file)
        print(f"  éœ€è¦è½‰æ›: {needs_convert}")
        if needs_convert:
            print(f"  åŸå› : {detailed_info.get('conversion_reasons', [])}")


def test_google_stt():
    """æ¸¬è©¦ Google STT åŠŸèƒ½"""
    print("\næ¸¬è©¦ Google STTï¼ˆä¿®æ­£ç‰ˆ v2ï¼‰")
    print("=" * 80)
    
    # åˆå§‹åŒ–æ¨¡å‹
    try:
        model = GoogleSTTModel(
            model="chirp_3",
            location="us",
            auto_convert_audio=True
        )
        model.print_config_info()
        print("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {e}")


if __name__ == "__main__":
    test_google_stt()
