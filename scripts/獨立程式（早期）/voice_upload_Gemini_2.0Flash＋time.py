# Gemini æ‰¹æ¬¡èªéŸ³è¾¨è­˜ + éŸ³æª”æ™‚é•·è³‡è¨Š
# pip install -U google-generativeai pydub

import os
import time
import google.generativeai as genai
from datetime import timedelta

#========================åƒæ•¸è¨­å®šå€==========================
# 1. è‡ªå‹•å°‹æ‰¾ API Key
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)

# å˜—è©¦å¾ç’°å¢ƒè®Šæ•¸æˆ–æª”æ¡ˆè®€å– API Key
API_KEY = os.getenv("GEMINI_API_KEY") or "AIzaSyC6qkLuKrlmzN6KC4I4WAV7uUhweD9LxH0"
genai.configure(api_key=API_KEY)

# 2. è³‡æ–™å¤¾è¨­å®š
INPUT_FOLDER = os.path.join(SCRIPT_DIR, "audio_input")
OUTPUT_FOLDER = os.path.join(SCRIPT_DIR, "transcripts_Gemini")
MODEL_NAME = "models/gemini-2.0-flash-exp"  # ä½¿ç”¨æœ€æ–°å¯¦é©—ç‰ˆ

# 3. æ”¯æ´çš„éŸ³æª”æ ¼å¼
SUPPORTED_EXT = {'.wav', '.mp3', '.m4a', '.aac', '.flac', '.ogg'}

# ================= æ·é‹å°ˆæ¥­è¡“èª Prompt =================
SYSTEM_INSTRUCTION = """
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ã€Œæ·é‹ç„¡ç·šé›»é€šè¨Šã€è½å¯«å°ˆå®¶ã€‚è«‹å°‡éŸ³è¨Šè½‰éŒ„ç‚ºç¹é«”ä¸­æ–‡é€å­—ç¨¿ã€‚
é€™æ®µéŒ„éŸ³åŒ…å«æ·é‹æ“ä½œè¡“èªã€æ•¸å­—ä»£ç¢¼èˆ‡ä¸­è‹±å¤¾é›œçš„æŒ‡ä»¤ï¼Œä¸”**æœ‰å…©ä½èªªè©±è€…**åœ¨å°è©±ã€‚

è«‹åš´æ ¼éµå®ˆä»¥ä¸‹è¾¨è­˜è¦å‰‡ï¼š

1. ã€èªªè©±è€…è¾¨è­˜ (Speaker Diarization)ã€‘:
   - éŒ„éŸ³ä¸­æœ‰ 2 ä½ä¸åŒçš„èªªè©±è€…ã€‚
   - è«‹å‹™å¿…å€åˆ†è²éŸ³ç‰¹å¾µï¼Œä¸¦åœ¨æ¯ä¸€å¥å°è©±å‰æ¨™ç¤º **[èªªè©±è€… 1]** æˆ– **[èªªè©±è€… 2]**ã€‚
   - å¦‚æœä½ èƒ½å¾å°è©±å…§å®¹æ˜ç¢ºåˆ¤æ–·è§’è‰²ï¼ˆä¾‹å¦‚ï¼šè¡Œæ§ä¸­å¿ƒ/OCC vs å¸æ©Ÿå“¡/è»Šçµ„ï¼‰ï¼Œè«‹ç›´æ¥ç”¨è§’è‰²åç¨±æ¨™ç¤ºã€‚
   - è¼¸å‡ºæ ¼å¼ç¯„ä¾‹ï¼š
     [è¡Œæ§ä¸­å¿ƒ]: å‘¼å«è»Šçµ„ï¼Œè«‹ç¢ºèªä½ç½®ã€‚
     [è»Šçµ„]: æ”¶åˆ°ï¼Œç›®å‰ä½ç½® G3ã€‚

2. ã€æ•¸å­—å”¸æ³•ä¿®æ­£ã€‘:
   - ã€Œæ´/å‹•ã€-> 0, ã€Œä¹ˆ/æ–ã€-> 1, ã€Œå…©ã€-> 2, ã€Œæ‹ã€-> 7, ã€Œå‹¾ã€-> 9
   - ç¯„ä¾‹ï¼šã€Œè»Šçµ„å‹•å‹¾æ–å‹•ã€ -> ã€Œè»Šçµ„ 0910ã€

3. ã€ç«™åèˆ‡ä»£è™Ÿã€‘:
   - ã€Œå·¨ä¸‰/å±…ä¸‰ã€ -> ã€ŒG3ã€(èˆŠç¤¾ç«™)
   - ã€Œå±…åã€ -> ã€ŒG10ã€(æ°´å®‰å®®ç«™)
   - ã€Œå±…åä¸‰ã€ -> ã€ŒG13ã€(å¤§æ…¶ç«™)

4. ã€å°ˆæ¥­è¡“èªã€‘:
   - ã€Œå·æ‹œPASS/ç™¾å¸•æ–¯ã€ -> ã€ŒBypassã€
   - ã€Œå“¦è¥¿ã€ -> ã€ŒOCCã€
   - ã€Œé˜¿Mã€ -> ã€ŒRMã€æˆ–ã€ŒAMã€æ¨¡å¼
   - ã€Œè»Šä¸»ã€ -> ã€Œè»Šçµ„ã€

5. ã€æ ¼å¼è¦æ±‚ã€‘:
   - è«‹è¼¸å‡ºå®Œæ•´å°è©±ï¼Œä¸è¦æ‘˜è¦ã€‚
   - æ¯ä¸€è¡Œéƒ½å¿…é ˆæœ‰èªªè©±è€…æ¨™ç±¤ã€‚
   - è«‹æŒ‰ç…§æ™‚é–“é †åºè¼¸å‡ºå°è©±ã€‚
"""

PROMPT_TEXT = "è«‹ä¾ç…§ä¸Šè¿°è¦å‰‡ï¼Œå€åˆ†å…©ä½èªªè©±è€…ä¸¦è½‰éŒ„ç‚ºç²¾ç¢ºçš„é€å­—ç¨¿ã€‚"
# ========================================================

def get_audio_duration(file_path):
    """
    å–å¾—éŸ³æª”æ™‚é•·ï¼ˆç§’ï¼‰
    éœ€è¦å®‰è£: pip install pydub
    """
    try:
        from pydub import AudioSegment
        audio = AudioSegment.from_file(file_path)
        duration_seconds = len(audio) / 1000.0  # pydub å›å‚³æ¯«ç§’
        return duration_seconds
    except ImportError:
        print("  âš ï¸  æœªå®‰è£ pydubï¼Œç„¡æ³•å–å¾—éŸ³æª”æ™‚é•·")
        print("  ğŸ’¡ åŸ·è¡Œ: pip install pydub")
        return None
    except Exception as e:
        print(f"  âš ï¸  ç„¡æ³•è®€å–éŸ³æª”æ™‚é•·: {e}")
        return None


def format_duration(seconds):
    """å°‡ç§’æ•¸è½‰ç‚ºå¯è®€æ ¼å¼"""
    if seconds is None:
        return "æœªçŸ¥"
    return str(timedelta(seconds=int(seconds)))


def add_metadata_header(filename, duration_seconds, transcript):
    """åœ¨é€å­—ç¨¿å‰é¢åŠ å…¥éŸ³æª”è³‡è¨Šæ¨™é ­"""
    header = f"""# èªéŸ³è¾¨è­˜çµæœ
# æª”æ¡ˆåç¨±: {filename}
# éŸ³æª”æ™‚é•·: {format_duration(duration_seconds)}
# è¾¨è­˜æ¨¡å‹: Gemini 2.0 Flash
# è¾¨è­˜æ™‚é–“: {time.strftime("%Y-%m-%d %H:%M:%S")}
# ================================================================

"""
    return header + transcript


def estimate_timestamps(transcript, total_duration):
    """
    ç°¡æ˜“æ™‚é–“æˆ³è¨˜ä¼°ç®—ï¼ˆåŸºæ–¼å¥å­æ•¸é‡å‡åˆ†ï¼‰
    âš ï¸ æ³¨æ„ï¼šé€™åªæ˜¯ç²—ç•¥ä¼°ç®—ï¼Œä¸å¦‚ Google STT ç²¾ç¢º
    """
    if total_duration is None:
        return transcript
    
    lines = [line.strip() for line in transcript.split('\n') if line.strip() and not line.startswith('#')]
    
    if not lines:
        return transcript
    
    # è¨ˆç®—æ¯å¥è©±çš„å¹³å‡æ™‚é•·
    avg_duration = total_duration / len(lines)
    
    timestamped_lines = []
    current_time = 0
    
    for line in lines:
        minutes = int(current_time // 60)
        seconds = current_time % 60
        timestamp = f"[{minutes:02d}:{seconds:05.2f}]"
        timestamped_lines.append(f"{timestamp} {line}")
        current_time += avg_duration
    
    return '\n'.join(timestamped_lines)


def process_batch():
    """æ‰¹æ¬¡è™•ç†ä¸»ç¨‹å¼"""
    
    # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
    if not os.path.exists(INPUT_FOLDER):
        print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥è³‡æ–™å¤¾: {INPUT_FOLDER}")
        print(f"ğŸ’¡ è«‹å»ºç«‹è³‡æ–™å¤¾ä¸¦æ”¾å…¥éŸ³æª”")
        return
    
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)

    # å–å¾—æ‰€æœ‰éŸ³æª”
    all_files = os.listdir(INPUT_FOLDER)
    audio_files = [f for f in all_files if os.path.splitext(f)[1].lower() in SUPPORTED_EXT]
    audio_files.sort()

    total_files = len(audio_files)
    
    if total_files == 0:
        print(f"âŒ åœ¨ '{INPUT_FOLDER}' ä¸­æ‰¾ä¸åˆ°æ”¯æ´çš„éŸ³æª”")
        print(f"ğŸ’¡ æ”¯æ´æ ¼å¼: {', '.join(SUPPORTED_EXT)}")
        return
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ Gemini æ‰¹æ¬¡è™•ç†æ¨¡å¼")
    print(f"{'='*60}")
    print(f"ğŸ“‚ è¼¸å…¥è³‡æ–™å¤¾: {INPUT_FOLDER}")
    print(f"ğŸ“‚ è¼¸å‡ºè³‡æ–™å¤¾: {OUTPUT_FOLDER}")
    print(f"ğŸ“Š æ‰¾åˆ° {total_files} å€‹éŸ³æª”")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    print(f"{'='*60}\n")

    model = genai.GenerativeModel(MODEL_NAME)
    
    success_count = 0
    fail_count = 0

    for index, filename in enumerate(audio_files, 1):
        file_path = os.path.join(INPUT_FOLDER, filename)
        
        print(f"\n[{index}/{total_files}] è™•ç†: {filename}")
        print(f"{'='*60}")
        
        # å–å¾—éŸ³æª”æ™‚é•·
        duration = get_audio_duration(file_path)
        if duration:
            print(f"ğŸµ éŸ³æª”æ™‚é•·: {format_duration(duration)}")

        try:
            # 1. ä¸Šå‚³
            print(f"  â˜ï¸  ä¸Šå‚³è‡³ Gemini API...", end="", flush=True)
            audio_file = genai.upload_file(path=file_path)
            print(f" âœ…")
            
            # 2. ç­‰å¾…è™•ç†
            print(f"  â³ ç­‰å¾…éŸ³æª”è½‰ç¢¼...", end="", flush=True)
            while audio_file.state.name == "PROCESSING":
                time.sleep(2)
                audio_file = genai.get_file(audio_file.name)
            
            if audio_file.state.name != "ACTIVE":
                print(f"\n  âŒ éŸ³æª”è™•ç†å¤±æ•— (ç‹€æ…‹: {audio_file.state.name})")
                fail_count += 1
                continue
            
            print(f" âœ…")

            # 3. AI è¾¨è­˜
            print(f"  ğŸ¤– Gemini è¾¨è­˜ä¸­...")
            response = model.generate_content(
                [SYSTEM_INSTRUCTION, PROMPT_TEXT, audio_file],
                request_options={"timeout": 600}  # 10åˆ†é˜è¶…æ™‚
            )
            
            transcript = response.text
            
            # 4. ç”¢ç”Ÿä¸‰ç¨®è¼¸å‡ºæ ¼å¼
            base_name = os.path.splitext(filename)[0]
            
            # æ ¼å¼ 1: å®Œæ•´é€å­—ç¨¿ï¼ˆå«æ¨™é ­ï¼‰
            full_output = os.path.join(OUTPUT_FOLDER, f"{base_name}_å®Œæ•´é€å­—ç¨¿.txt")
            with open(full_output, "w", encoding="utf-8") as f:
                content = add_metadata_header(filename, duration, transcript)
                f.write(content)
            
            # æ ¼å¼ 2: ç°¡æ˜“æ™‚é–“æˆ³è¨˜ç‰ˆï¼ˆä¼°ç®—ï¼‰
            timestamp_output = os.path.join(OUTPUT_FOLDER, f"{base_name}_æ™‚é–“ä¼°ç®—.txt")
            with open(timestamp_output, "w", encoding="utf-8") as f:
                timestamped = estimate_timestamps(transcript, duration)
                f.write(add_metadata_header(filename, duration, timestamped))
            
            # æ ¼å¼ 3: ç´”æ–‡å­—ï¼ˆç„¡æ¨™é ­ï¼Œæ–¹ä¾¿å¾Œè™•ç†ï¼‰
            plain_output = os.path.join(OUTPUT_FOLDER, f"{base_name}_ç´”æ–‡å­—.txt")
            with open(plain_output, "w", encoding="utf-8") as f:
                f.write(transcript)
            
            # 5. é¡¯ç¤ºé è¦½
            preview = transcript[:100].replace('\n', ' ')
            print(f"  ğŸ“„ è¾¨è­˜çµæœé è¦½: {preview}...")
            
            print(f"  âœ… è½‰éŒ„å®Œæˆï¼")
            print(f"     ğŸ“„ {os.path.basename(full_output)}")
            print(f"     ğŸ“„ {os.path.basename(timestamp_output)}")
            print(f"     ğŸ“„ {os.path.basename(plain_output)}")

            # 6. æ¸…ç†é›²ç«¯æš«å­˜æª”
            audio_file.delete()
            print(f"  ğŸ—‘ï¸  å·²æ¸…ç† API æš«å­˜æª”")
            
            success_count += 1

        except Exception as e:
            print(f"  âŒ è™•ç†å¤±æ•—: {e}")
            fail_count += 1
        
        # é¿å…è§¸ç™¼ API é »ç‡é™åˆ¶
        if index < total_files:
            time.sleep(2)

    # ç¸½çµå ±å‘Š
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æ‰¹æ¬¡è™•ç†å®Œæˆ")
    print(f"{'='*60}")
    print(f"âœ… æˆåŠŸ: {success_count} å€‹æª”æ¡ˆ")
    print(f"âŒ å¤±æ•—: {fail_count} å€‹æª”æ¡ˆ")
    print(f"ğŸ“‚ çµæœå·²å„²å­˜è‡³: {OUTPUT_FOLDER}")
    print(f"{'='*60}\n")
    
    print("âš ï¸  æ³¨æ„äº‹é …:")
    print("â€¢ Gemini ä¸æ”¯æ´ç²¾ç¢ºçš„å–®å­—å±¤ç´šæ™‚é–“æˆ³è¨˜")
    print("â€¢ æ™‚é–“ä¼°ç®—ç‰ˆåƒ…ä¾›åƒè€ƒï¼ŒåŸºæ–¼å¥å­æ•¸é‡å‡åˆ†æ™‚é•·")
    print("â€¢ å¦‚éœ€ç²¾ç¢ºæ™‚é–“æˆ³ï¼Œå»ºè­°ä½¿ç”¨ Google Speech-to-Text")


if __name__ == "__main__":
    process_batch()