# æª”æ¡ˆä½ç½® aiSpeech/scripts/model_whisper.py
import whisper
import torch

# å…¨åŸŸè®Šæ•¸ï¼Œç”¨ä¾†æš«å­˜è¼‰å…¥å¥½çš„æ¨¡å‹ï¼Œé¿å…é‡è¤‡è¼‰å…¥
_loaded_model = None
_curerent_model_size = None

def load_model_once(model_size = "large-v3"):
    """
    ç¢ºä¿æ¨¡å‹åªè¢«è¼‰å…¥ä¸€æ¬¡çš„å–®ä¾‹æ¨¡å¼ï¼ˆSingleton Patternï¼‰
    ä¸¦ä¿ç•™åŸæœ¬çš„M2 GPUåŠ é€Ÿåˆ¤æ–·é‚è¼¯
    """
    global _loaded_model, _curerent_model_size

    # å¦‚æœæ¨¡å‹å·²ç¶“è¼‰å…¥ä¸”å¤§å°ä¸€æ¨£ï¼Œç›´æ¥å›å‚³
    if _loaded_model is not None and _curerent_model_size == model_size:
        return _loaded_model
    print(f"ğŸ”„ æ­£åœ¨è¼‰å…¥ Whisperæ¨¡å‹ ({model_size})...")

    # åµæ¸¬ M2/M3 Macçš„MPSåŠ é€Ÿ
    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    
    try:
        _loaded_model = whisper.load_model(model_size, device=device)
        print(f"âœ… Whisperæ¨¡å‹ ({model_size}) è¼‰å…¥å®Œæˆï¼Œä½¿ç”¨è£ç½®: {device.upper()}")
    except Exception as e:
        print(f"âŒ {device}å•Ÿç”¨å¤±æ•—ï¼Œåˆ‡å›CPUæ¨¡å¼ï¼š{e}")
        _loaded_model = whisper.load_model(model_size, device="cpu")
        
    _curerent_model_size = model_size
    return _loaded_model

def transcribe_with_whisper(audio_path, model_size = "large-v3"):
    """
    ç•¶ä¸€æª”æ¡ˆè¾¨è­˜å‡½æ•¸
    """
    # 1. å–å¾—æ¨¡å‹å¯¦é«”
    model = load_model_once(model_size)
    
    # 2. è¨­å®šæç¤ºè©(prompt)-ä¿ç•™æ ¸å¿ƒpromt
    prompt_text = "é€™æ˜¯ä¸€æ®µæ·é‹ç„¡ç·šé›»é€šè¨Š,è¡“èªåŒ…å«:OCCè¡Œæ§ä¸­å¿ƒ, å‘¼å«, ç«‹å³è‡³ä¸€æœˆå°, 09, 10, ç•°ç‰©, æ–¹å½¢é‘°åŒ™, 05è»Šé–€, Bypassã€‚"

    # 3. é€²è¡Œè¾¨è­˜
    # initial_promptæ˜¯é—œéµ
    result = model.transcribe(
        audio_path,
        language="zh",
        initial_prompt=prompt_text,
    )
    return result['text']