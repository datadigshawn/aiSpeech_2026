# voice_local_whisper_optimized.py
import os
import time
import whisper
from datetime import timedelta

# ================= âš™ï¸ è¨­å®šå€ =================
INPUT_FOLDER = "audio_input"           # æ”¾éŸ³æª”çš„è³‡æ–™å¤¾
OUTPUT_FOLDER = "transcripts_Whisper"  # å­˜çµæœçš„è³‡æ–™å¤¾
MODEL_TYPE = "large-v3"                   # M2 æ¨è–¦ç”¨ turboï½œå‡å¦‚è¾¨è­˜åº¦èƒ½ä¸æ»¿æ„ï¼Œå¯ä»¥æ”¹ç”¨ large-v3

# æ”¯æ´çš„æª”æ¡ˆæ ¼å¼
SUPPORTED_EXT = {'.wav', '.mp3', '.m4a', '.aac', '.flac', '.ogg'}

# ================= ğŸ”§ å„ªåŒ–ç­–ç•¥ï¼šå¾Œè™•ç†å­—å…¸ =================
# é€™æ˜¯æ‚¨çš„æ ¸å¿ƒéœ€æ±‚ï¼šæŠŠè½éŒ¯çš„ç„¡ç·šé›»è¡“èªå¼·åˆ¶ä¿®æ­£å›ä¾†
REPLACEMENT_RULES = {
    "æ­è¥¿": "OCC",
    "å“¦è¥¿": "OCC",
    "è­·ç…§": "å‘¼å«",
    "ç«‹å³è‡´": "ç«‹å³è‡³",
    "æ´æº": "09",   # ç„¡ç·šé›»ç‰¹æ®Šè®€éŸ³
    "å‹•å‹¾": "09",
    "æ´": "0",      # å–®ç¨å‡ºç¾æ™‚
    "å‹¾": "9",      # å–®ç¨å‡ºç¾æ™‚
    "è…°å‹•": "10",
    "ä¹ˆæ´": "10",
    "ä¹ˆ": "1",
    "ç¾©å‹™": "ç•°ç‰©",
    "æ–¹è¡Œé‘°åŒ™": "æ–¹å½¢é‘°åŒ™",
    "å‹•ç‰©è»Šé–€": "05è»Šé–€",
    "å‹•äº”": "05",
    "å·æ‹œPASS": "Bypass",
    "ç™¾å¸•æ–¯": "Bypass",
}

def post_process_text(text):
    """
    åŸ·è¡Œæ–‡å­—æ›¿æ›ï¼Œå°‡å¸¸è¦‹éŒ¯èª¤ä¿®æ­£å›ä¾†
    """
    # 1. å…ˆåŸ·è¡Œå­—å…¸æ›¿æ›
    for wrong, correct in REPLACEMENT_RULES.items():
        text = text.replace(wrong, correct)
    
    # 2. é¡å¤–çš„æ ¼å¼æ•´ç† (å¯é¸)
    # æ¯”å¦‚æŠŠ "G 3" çš„ç©ºç™½æ‹¿æ‰è®Šæˆ "G3"
    text = text.replace("G 3", "G3").replace("G 10", "G10")
    
    return text.strip()

# =======================================================

def run_local_pipeline():
    # 1. æº–å‚™è³‡æ–™å¤¾
    if not os.path.exists(OUTPUT_FOLDER):
        os.makedirs(OUTPUT_FOLDER)
    if not os.path.exists(INPUT_FOLDER):
        print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥è³‡æ–™å¤¾ï¼š{INPUT_FOLDER}")
        return
    
    files = [f for f in os.listdir(INPUT_FOLDER) if os.path.splitext(f)[1].lower() in SUPPORTED_EXT]
    files.sort()

    if not files:
        print("âŒ è³‡æ–™å¤¾å…§æ²’æœ‰æ”¯æ´çš„éŸ³æª”ã€‚")
        return

    # 2. è¼‰å…¥æ¨¡å‹ (å˜—è©¦å•Ÿç”¨ M2 GPU)
    print(f"ğŸ”„ è¼‰å…¥ Whisper æ¨¡å‹ ({MODEL_TYPE})...")
    try:
        model = whisper.load_model(MODEL_TYPE, device="mps")
        print("âš¡ï¸ æˆåŠŸå•Ÿç”¨ M2 GPU åŠ é€Ÿæ¨¡å¼ (MPS)ï¼")
    except Exception as e:
        print(f"âš ï¸ GPU å•Ÿç”¨å¤±æ•—ï¼Œåˆ‡æ›å› CPU æ¨¡å¼: {e}")
        model = whisper.load_model(MODEL_TYPE)

    print(f"âœ… é–‹å§‹è™•ç† {len(files)} å€‹æª”æ¡ˆ...\n")

    # 3. åŸ·è¡Œè¾¨è­˜
    for i, filename in enumerate(files):
        file_path = os.path.join(INPUT_FOLDER, filename)
        output_filename = os.path.splitext(filename)[0] + ".txt"
        output_path = os.path.join(OUTPUT_FOLDER, output_filename)

        print(f"â–¶ï¸ [{i+1}/{len(files)}] æ­£åœ¨è™•ç†ï¼š{filename}")
        start_time = time.time()

        try:
            # === Whisper è¾¨è­˜ ===
            # initial_prompt æ˜¯ Whisper å”¯ä¸€èƒ½æ¥å—çš„ã€Œæç¤ºã€
            # æˆ‘å€‘æŠŠé‡è¦çš„é—œéµå­—æ”¾åœ¨é€™è£¡ï¼Œæš—ç¤ºæ¨¡å‹
            result = model.transcribe(
                file_path,
                language="zh",
                initial_prompt="é€™æ˜¯ä¸€æ®µå°ç£æ·é‹ç„¡ç·šé›»é€šè¨Šã€‚è¡“èªåŒ…å«ï¼šOCCè¡Œæ§ä¸­å¿ƒ, å‘¼å«, ç«‹å³è‡³ä¸€æœˆå°, 09, 10, ç•°ç‰©, æ–¹å½¢é‘°åŒ™, 05è»Šé–€, Bypassã€‚"
            )

            # === å¾Œè™•ç†ä¿®æ­£ (Python å¼·åˆ¶æ›¿æ›) ===
            raw_text = result["text"]
            refined_text = post_process_text(raw_text)

            # === å­˜æª” ===
            duration = time.time() - start_time
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(refined_text)
            
            print(f"   âœ… å®Œæˆï¼è€—æ™‚: {str(timedelta(seconds=int(duration)))}")

        except Exception as e:
            print(f"   âŒ è™•ç†å¤±æ•—ï¼š{e}")

    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼çµæœè«‹æŸ¥çœ‹ï¼š{OUTPUT_FOLDER}")

if __name__ == "__main__":
    run_local_pipeline()